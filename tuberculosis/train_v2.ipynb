{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2940 images belonging to 2 classes.\n",
      "Found 633 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "91/91 [==============================] - 319s 3s/step - loss: 0.1513 - accuracy: 0.9519 - val_loss: 1.5767 - val_accuracy: 0.9062\n",
      "Epoch 2/10\n",
      "91/91 [==============================] - 315s 3s/step - loss: 0.0840 - accuracy: 0.9725 - val_loss: 0.7959 - val_accuracy: 0.7911\n",
      "Epoch 3/10\n",
      "91/91 [==============================] - 312s 3s/step - loss: 0.0764 - accuracy: 0.9739 - val_loss: 1.1979 - val_accuracy: 0.8816\n",
      "Epoch 4/10\n",
      "91/91 [==============================] - 315s 3s/step - loss: 0.0599 - accuracy: 0.9852 - val_loss: 1.9868 - val_accuracy: 0.4211\n",
      "Epoch 5/10\n",
      "91/91 [==============================] - 313s 3s/step - loss: 0.0623 - accuracy: 0.9804 - val_loss: 0.2267 - val_accuracy: 0.9013\n",
      "Epoch 6/10\n",
      "91/91 [==============================] - 312s 3s/step - loss: 0.0656 - accuracy: 0.9766 - val_loss: 5.0699 - val_accuracy: 0.1793\n",
      "Epoch 7/10\n",
      "91/91 [==============================] - 322s 4s/step - loss: 0.0635 - accuracy: 0.9783 - val_loss: 0.0483 - val_accuracy: 0.9934\n",
      "Epoch 8/10\n",
      "91/91 [==============================] - 306s 3s/step - loss: 0.0392 - accuracy: 0.9873 - val_loss: 0.2858 - val_accuracy: 0.9326\n",
      "Epoch 9/10\n",
      "91/91 [==============================] - 308s 3s/step - loss: 0.0420 - accuracy: 0.9856 - val_loss: 0.6048 - val_accuracy: 0.7582\n",
      "Epoch 10/10\n",
      "91/91 [==============================] - 309s 3s/step - loss: 0.0409 - accuracy: 0.9852 - val_loss: 2.6231 - val_accuracy: 0.5592\n",
      "Found 2940 images belonging to 2 classes.\n",
      "Found 633 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "91/91 [==============================] - 313s 3s/step - loss: 0.1456 - accuracy: 0.9529 - val_loss: 18.2538 - val_accuracy: 0.1760\n",
      "Epoch 2/10\n",
      "91/91 [==============================] - 308s 3s/step - loss: 0.0804 - accuracy: 0.9694 - val_loss: 1.4138 - val_accuracy: 0.8882\n",
      "Epoch 3/10\n",
      "91/91 [==============================] - 310s 3s/step - loss: 0.0972 - accuracy: 0.9684 - val_loss: 0.7601 - val_accuracy: 0.8569\n",
      "Epoch 4/10\n",
      "91/91 [==============================] - 310s 3s/step - loss: 0.0672 - accuracy: 0.9790 - val_loss: 0.9132 - val_accuracy: 0.9030\n",
      "Epoch 5/10\n",
      "91/91 [==============================] - 306s 3s/step - loss: 0.0474 - accuracy: 0.9869 - val_loss: 0.1094 - val_accuracy: 0.9786\n",
      "Epoch 6/10\n",
      "91/91 [==============================] - 309s 3s/step - loss: 0.0874 - accuracy: 0.9708 - val_loss: 0.1677 - val_accuracy: 0.9178\n",
      "Epoch 7/10\n",
      "91/91 [==============================] - 307s 3s/step - loss: 0.0591 - accuracy: 0.9807 - val_loss: 1.6752 - val_accuracy: 0.6414\n",
      "Epoch 8/10\n",
      "91/91 [==============================] - 308s 3s/step - loss: 0.0632 - accuracy: 0.9783 - val_loss: 6.6834 - val_accuracy: 0.2599\n",
      "Found 2940 images belonging to 2 classes.\n",
      "Found 633 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "91/91 [==============================] - 313s 3s/step - loss: 0.1438 - accuracy: 0.9529 - val_loss: 4.2025 - val_accuracy: 0.5049\n",
      "Epoch 2/10\n",
      "91/91 [==============================] - 310s 3s/step - loss: 0.0809 - accuracy: 0.9697 - val_loss: 1.3987 - val_accuracy: 0.7237\n",
      "Epoch 3/10\n",
      "91/91 [==============================] - 307s 3s/step - loss: 0.0724 - accuracy: 0.9763 - val_loss: 0.1090 - val_accuracy: 0.9572\n",
      "Epoch 4/10\n",
      "91/91 [==============================] - 305s 3s/step - loss: 0.0450 - accuracy: 0.9852 - val_loss: 0.4236 - val_accuracy: 0.8898\n",
      "Epoch 5/10\n",
      "91/91 [==============================] - 305s 3s/step - loss: 0.0519 - accuracy: 0.9849 - val_loss: 0.7802 - val_accuracy: 0.9030\n",
      "Epoch 6/10\n",
      "91/91 [==============================] - 306s 3s/step - loss: 0.0626 - accuracy: 0.9780 - val_loss: 1.6509 - val_accuracy: 0.8766\n",
      "Found 630 images belonging to 2 classes.\n",
      "20/20 [==============================] - 17s 774ms/step\n",
      "20/20 [==============================] - 17s 771ms/step\n",
      "20/20 [==============================] - 17s 773ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.92      0.88       525\n",
      "           1       0.20      0.10      0.13       105\n",
      "\n",
      "    accuracy                           0.78       630\n",
      "   macro avg       0.52      0.51      0.50       630\n",
      "weighted avg       0.73      0.78      0.75       630\n",
      "\n",
      "[[484  41]\n",
      " [ 95  10]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define paths to your training, validation, and testing data\n",
    "train_data_dir = '/Users/arshdeepsingh/Documents/tuberculosis_detection_v2/train'\n",
    "val_data_dir = '/Users/arshdeepsingh/Documents/tuberculosis_detection_v2/validation'\n",
    "test_data_dir = '/Users/arshdeepsingh/Documents/tuberculosis_detection_v2/test'\n",
    "\n",
    "# Data preprocessing and augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Set the input image size for DenseNet model\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "# Batch size for training and validation\n",
    "batch_size = 32\n",
    "\n",
    "# Define the number of models in the ensemble\n",
    "num_models = 3\n",
    "\n",
    "# Define epochs and early stopping criteria\n",
    "epochs = 10\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Function to create and compile model\n",
    "def create_model():\n",
    "    base_model = DenseNet121(weights='imagenet', include_top=False)\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    predictions = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    model.compile(optimizer=Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Initialize list to store models\n",
    "models = []\n",
    "\n",
    "# Train multiple models with different architectures or initializations\n",
    "for i in range(num_models):\n",
    "    # Prepare train and validation data\n",
    "    train_generator = train_datagen.flow_from_directory(train_data_dir, target_size=(img_width, img_height), batch_size=batch_size, class_mode='binary')\n",
    "    val_generator = val_test_datagen.flow_from_directory(val_data_dir, target_size=(img_width, img_height), batch_size=batch_size, class_mode='binary')\n",
    "\n",
    "    # Create and train the model\n",
    "    model = create_model()\n",
    "    model.fit(train_generator, steps_per_epoch=train_generator.samples // batch_size, epochs=epochs, validation_data=val_generator, validation_steps=val_generator.samples // batch_size, callbacks=[early_stopping])\n",
    "    \n",
    "    # Add trained model to list\n",
    "    models.append(model)\n",
    "\n",
    "# Evaluate ensemble model on test data\n",
    "test_generator = val_test_datagen.flow_from_directory(test_data_dir, target_size=(img_width, img_height), batch_size=batch_size, class_mode='binary')\n",
    "predictions = np.mean([model.predict(test_generator) for model in models], axis=0)\n",
    "predictions_binary = np.round(predictions)\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Generate classification report and confusion matrix for ensemble predictions\n",
    "print(classification_report(y_true, predictions_binary))\n",
    "print(confusion_matrix(y_true, predictions_binary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('tb3_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 16s 777ms/step - loss: 0.1230 - accuracy: 0.9492\n",
      "Test Loss: 0.12301963567733765\n",
      "Test Accuracy: 0.9492063522338867\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "\n",
    "# Print the test loss and accuracy\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 16s 776ms/step - loss: 0.1110 - accuracy: 0.9542\n",
      "Validation Loss: 0.11097970604896545\n",
      "Validation Accuracy: 0.9541864395141602\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation set\n",
    "val_loss, val_accuracy = model.evaluate(val_generator)\n",
    "\n",
    "# Print validation loss and accuracy\n",
    "print(\"Validation Loss:\", val_loss)\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
